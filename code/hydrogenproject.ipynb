{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pyspark.mllib.tree import RandomForest, RandomForestModel\n",
    "from pyspark.mllib.util import MLUtils\n",
    "import numpy\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = sc.textFile(\"swift://Notebooks.spark/hydrogendata.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The first line in the 2015.csv dataset: [u'1.000057,646,0.124937,37.4,22.501,-15.7', u'2.000114,646,0.299909,37.4,22.5999,-15.7']\n"
     ]
    }
   ],
   "source": [
    "print \"The first line in the 2015.csv dataset:\", data.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def config_spark_acct(name, auth_url, tenant_id, username, password):\n",
    "   prefix = \"fs.swift.service.\" + name \n",
    "   hconf = sc._jsc.hadoopConfiguration()\n",
    "   hconf.set(prefix + \".auth.url\", auth_url + \"/\" + tenant_id)\n",
    "   hconf.set(prefix + \".username\", username)\n",
    "   hconf.set(prefix + \".auth.endpoint.prefix\", \"endpoints\")\n",
    "   hconf.setInt(prefix + \".http.port\", 8080)\n",
    "   hconf.set(prefix + \".apikey\", password)\n",
    "   hconf.setBoolean(prefix + \".public\", True)\n",
    "   hconf.set(prefix + \".use.get.auth\", \"basic64\")\n",
    "   hconf.setBoolean(prefix + \".location-aware\", False)\n",
    "   hconf.set(prefix + \".password\", password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config_spark_acct(\"myacct\",'https://identity.open.softlayer.com','d58f4bebc9c24fbf813ec53473e2ec9c','user_ce1c2baedfc5e647982f4681b8f177350ea4cce8','H}.cv0^3FqvW=#Ke')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MapPartitionsRDD[4] at textFile at NativeMethodAccessorImpl.java:-2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.textFile(\"swift://Notebooks.myacct/hydrogendata.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DataParse = data.map(lambda line : line.split(\",\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[u'1.000057', u'646', u'0.124937', u'37.4', u'22.501', u'-15.7']]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataParse.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1.000057', u'646', u'0.124937', u'37.4', u'22.501', u'-15.7']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DataParse.take(2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext, Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Separate the header line from the data, and drop the row index\n",
    "hydrogendata = DataParse.map(lambda x: [float(x[0]), float(x[1]), float(x[2]), float(x[3]), float(x[4]), float(x[5])]).toDF([\"Time\",\"VehiclePressure\",\"FlowRate\",\"VehicleTemp\",\"AmbientTemp\",\"ChillerCoilTemp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Time: double (nullable = true)\n",
      " |-- VehiclePressure: double (nullable = true)\n",
      " |-- FlowRate: double (nullable = true)\n",
      " |-- VehicleTemp: double (nullable = true)\n",
      " |-- AmbientTemp: double (nullable = true)\n",
      " |-- ChillerCoilTemp: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "hydrogendata.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our 5 features are: Time, FlowRate, VehicleTemp, AmbientTemp, ChillerCoilTemp\n"
     ]
    }
   ],
   "source": [
    "#Separate out the label column.\n",
    "labelCol = \"VehiclePressure\"\n",
    "# Get a list of feature column labels.\n",
    "featureCols = filter(lambda c: c != labelCol, map(lambda c: c.name, hydrogendata.schema.fields))\n",
    "numFeatures = len(featureCols)#\n",
    "print 'Our %d features are: %s' % (len(featureCols), \", \".join(featureCols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.mllib.regression import LabeledPoint\n",
    "from pyspark.mllib.util import MLUtils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def indexColumn(col):\n",
    "  \"\"\" Return dictionary for column: original value -> 0-based index \"\"\"\n",
    "  distinctValues = sorted(hydrogendata.select(col).distinct().collect())\n",
    "  # Map Row(value) to value:\n",
    "  distinctValues = map(lambda row: row[0], distinctValues)\n",
    "  return dict([(distinctValues[i], i) for i in xrange(len(distinctValues))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def reIndexRow(row):\n",
    "  \n",
    "  featureVector = numpy.zeros(len(row))\n",
    "  for j in xrange(len(featureCols)):\n",
    "   return Vectors.dense(featureVector)\n",
    "# Create RDD of feature vectors using the function defined above.\n",
    "indexedFeatures = hydrogendata.select(*featureCols).map(lambda row: reIndexRow(row))\n",
    "# Create corresponding RDD of labels \n",
    "vp = hydrogendata.select(labelCol).map(lambda row: row[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create an RDD of LabeledPoints.\n",
    "indexedvp = vp.zip(indexedFeatures).map(lambda l_p: LabeledPoint(l_p[0], l_p[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "(trainingData, testData) = indexedvp.randomSplit([0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PythonRDD[26] at RDD at PythonRDD.scala:43"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainingData.cache()\n",
    "testData.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RandomForest.trainRegressor(trainingData, categoricalFeaturesInfo={},\n",
    "                                    numTrees=8, featureSubsetStrategy=\"auto\",\n",
    "                                    impurity='variance', maxDepth=24, maxBins=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions = model.predict(testData.map(lambda x: x.features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labelsAndPredictions = testData.map(lambda lp: lp.label).zip(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Mean Squared Error = 46612.3474187\n",
      "Learned regression forest model:\n",
      "TreeEnsembleModel regressor with 8 trees\n",
      "\n",
      "  Tree 0:\n",
      "    Predict: 441.63430866886216\n",
      "  Tree 1:\n",
      "    Predict: 443.65025477855977\n",
      "  Tree 2:\n",
      "    Predict: 440.7397622602904\n",
      "  Tree 3:\n",
      "    Predict: 443.08489351205026\n",
      "  Tree 4:\n",
      "    Predict: 444.1960029581033\n",
      "  Tree 5:\n",
      "    Predict: 442.6248831349886\n",
      "  Tree 6:\n",
      "    Predict: 443.77263613062075\n",
      "  Tree 7:\n",
      "    Predict: 443.40950869634804\n",
      "\n"
     ]
    }
   ],
   "source": [
    "testMSE = labelsAndPredictions.map(lambda (v, p): (v - p) * (v - p)).sum() /\\\n",
    "    float(testData.count())\n",
    "print('Test Mean Squared Error = ' + str(testMSE))\n",
    "print('Learned regression forest model:')\n",
    "print(model.toDebugString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TreeEnsembleModel regressor with 8 trees\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}